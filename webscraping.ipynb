{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> webscraping\n",
    "\n",
    "### première partie du projet bloc 1\n",
    "\n",
    "- Webscraping du site [www.allocine.fr](https://www.allocine.fr/films/)\n",
    "\n",
    "![filtres](images/filtresSMALL.png)\n",
    "\n",
    "## Sources :\n",
    "[beautiful-soup-4](https://beautiful-soup-4.readthedocs.io/en/latest/)<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "#import httpx\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "%config IPCompleter.greedy = True\n",
    "\n",
    "url_site = 'https://www.allocine.fr/films/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On scrape tous les genres de film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "# Scrap all categories\n",
    "r = requests.get(url_site, auth=('user', 'pass'))\n",
    "if r.status_code != 200:\n",
    "    print(\"url_site error\")\n",
    "    \n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "print(type(soup))\n",
    "\n",
    "categories = []\n",
    "eltCategories = soup.find('div', class_='filter-entity-section')\n",
    "for elt in eltCategories.find_all('li'):\n",
    "    categories.append(elt.a.text)\n",
    "\n",
    "df_categories = pd.Series(categories)\n",
    "\n",
    "dict_n_cat = {k:v for k, v in enumerate(categories)}\n",
    "dict_cat_n = {v:k for v, k in dict_n_cat.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On scrapte les films par période\n",
    "[1980 - 1989] puis [1990 - 1999] ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2030 - 2039\n",
      "2020 - 2029\n",
      "2010 - 2019\n",
      "2000 - 2009\n",
      "1990 - 1999\n",
      "** 1980 - 1989\n",
      "1970 - 1979\n",
      "1960 - 1969\n",
      "1950 - 1959\n",
      "1940 - 1949\n",
      "1930 - 1939\n",
      "1920 - 1929\n",
      "1910 - 1919\n",
      "1900 - 1909\n",
      "1890 - 1899\n"
     ]
    }
   ],
   "source": [
    "# Scrap url of years we want to scrap the movies\n",
    "# Not Working\n",
    "# I cannot get the url by scraping\n",
    "decades_to_scrap = ['1980 - 1989']\n",
    "eltYears = eltCategories.find_next_sibling()\n",
    "lstUrl = []\n",
    "eltCur = eltYears.find('li')\n",
    "\n",
    "while eltCur:\n",
    "    text = eltCur.span.text\n",
    "    # print(eltCur)\n",
    "    # print(eltCur.span.get('href'))\n",
    "    if text in decades_to_scrap:\n",
    "        print(\"**\", text)\n",
    "    else:\n",
    "        print(eltCur.span.text)\n",
    "    eltCur = eltCur.find_next_sibling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ou bien nous pouvons entrer les url manuellement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "url_decades = url_site + 'decennie-1980/'\n",
    "url_year = url_site + 'decennie-1980/annee-1980/'\n",
    "\n",
    "def getNumberOfPages(elt):\n",
    "    nb = 0\n",
    "    while elt:\n",
    "        if elt.text.isdigit():\n",
    "            nb = elt.text\n",
    "        elt = elt.find_next_sibling()\n",
    "    return int(nb)\n",
    "\n",
    "r = requests.get(url_year, auth=('user', 'pass'))\n",
    "if r.status_code != 200:\n",
    "    print(\"url_site error\")\n",
    "\n",
    "# We get the number of pages for this year\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "pagination = soup.find('div', class_='pagination-item-holder')\n",
    "nb_pages = int(pagination.find_all('span')[-1].text)\n",
    "assert nb_pages == getNumberOfPages(pagination.find('span'))\n",
    "print(nb_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On scrape chaque page de films pour une année donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shining\n",
      "\n",
      "\n",
      "La Chasse - Cruising\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def scrapMoviePage(soupMovies):\n",
    "    #print(soupMovies)\n",
    "    elt = soupMovies.find('li', class_='mdl')\n",
    "    elt = elt.find(\"h2\")\n",
    "#    print(elt)\n",
    "    url_movie = elt.find('a').get('href')\n",
    "#    print(url_movie)\n",
    "    print(elt.text)\n",
    "    \n",
    "n_test = 3\n",
    "for i in range(1, n_test):\n",
    "    url_year_page = url_year + '?page=' + str(i)\n",
    "    #print(url_year_page)\n",
    "    r = requests.get(url_year_page, auth=('user', 'pass'))\n",
    "    if r.status_code != 200:\n",
    "        print(\"url_site error\")        \n",
    "    soupMovies = BeautifulSoup(r.content, 'html.parser')\n",
    "    scrapMoviePage(soupMovies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On scrape les pays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eltCountries = eltYears.find_next_sibling()\n",
    "print(eltCountries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "block1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
