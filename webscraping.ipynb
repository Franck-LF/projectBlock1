{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> **Webscraping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Présentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Webscraping du site [www.allocine.fr](https://www.allocine.fr/films/) avec Beautiful Soup et Selenium.\n",
    "\n",
    "Nous vérifions tout d'abord le fichier \"robots.txt\" pour voir si nous sommes autorisés à scraper le film.\n",
    "\n",
    "![robots.txt](images/robots.txt.png)\n",
    "\n",
    "Il n'y a pas de limitation pour notre tâche puisque nous travaillons sous l'url : <code>https://www.allocine.fr/film/</code><br>\n",
    "\n",
    "Ensuite nous allons sur le site allocine, catégorie **films** et nous allons scraper les informations à partir des menus déroulants sur la gauche (les catégories de films, les pays et ensuite nous scraperons les films par année).\n",
    "\n",
    "![filtres](images/filtresSMALL.png)\n",
    "### Sources :\n",
    "**Beautiful Soup** :\n",
    "[beautiful-soup-4](https://beautiful-soup-4.readthedocs.io/en/latest/)<br>\n",
    "[beautiful-soup-4.readthedocs.io](https://beautiful-soup-4.readthedocs.io/en/latest/#searching-the-tree)<br>\n",
    "\n",
    "**Selenium** :<br>\n",
    "[selenium-python.readthedocs.io](https://selenium-python.readthedocs.io/locating-elements.html)<br>\n",
    "[selenium.dev/documentation](https://www.selenium.dev/documentation/webdriver/elements/information/)<br>\n",
    "[selenium.dev/documentation/finders/](https://www.selenium.dev/documentation/webdriver/elements/finders/)<br>\n",
    "[geeksforgeeks.org/get_property-selenium/](https://www.geeksforgeeks.org/get_property-element-method-selenium-python/)<br>\n",
    "\n",
    "Les liens sont sûrement générés aléatoirement dynamiquement, on peut utiliser XPath avec selenium<br>\n",
    "ou bien avec lxml ??<br>\n",
    "\n",
    "Sur ce lien https://medium.com/swlh/web-scraping-using-selenium-and-beautifulsoup-adfc8810240a Selenium est utilisé pour faire le scraping des urls puis ensuite beautiful soup est utilisé pour faire le scraping des pages de chaque urls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import io\n",
    "import math\n",
    "import copy\n",
    "import httpx\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# One way to set the driver options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "def _options():\n",
    "    ''' Another way to set the options '''\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('--test-type')\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--incognito')\n",
    "    options.add_argument('--disable-gpu') if os.name == 'nt' else None # Windows workaround\n",
    "    options.add_argument('--verbose')\n",
    "    return options\n",
    "\n",
    "%config IPCompleter.greedy = True\n",
    "\n",
    "url_site  = 'https://www.allocine.fr/'\n",
    "url_films = 'https://www.allocine.fr/films/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Scraping the movies**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **On scrape la liste des genres de film**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n",
      "Nb categories : 37\n"
     ]
    }
   ],
   "source": [
    "# Scrap all categories\n",
    "r = requests.get(url_films, auth=('user', 'pass'))\n",
    "if r.status_code != 200:\n",
    "    print(\"url_site error\")\n",
    "\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "print(type(soup))\n",
    "\n",
    "categories = []\n",
    "elt_categories = soup.find('div', class_='filter-entity-section')\n",
    "for elt in elt_categories.find_all('li'):\n",
    "    #print(elt.prettify())\n",
    "    categories.append(elt.a.text)\n",
    "\n",
    "print(\"Nb categories :\", len(categories))\n",
    "ds_categories = pd.Series(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **On scrape la liste des pays d'origine des films**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France', 'U.S.A.', 'Afrique du Sud', 'Albanie', 'Algérie', 'Allemagne', \"Allemagne de l'Est\", \"Allemagne de l'Ouest\", 'Arabie Saoudite', 'Argentine', 'Arménie', 'Australie', 'Autriche', 'Belgique', 'Bengladesh', 'Bolivie', 'Bosnie-Herzégovine', 'Brésil', 'Bulgarie', 'Burkina Faso', 'Cambodge', 'Cameroun', 'Canada', 'Chili', 'Chine', 'Chypre', 'Colombie', 'Corée', 'Corée du Sud', 'Croatie', 'Cuba', \"Côte-d'Ivoire\", 'Danemark', 'Egypte', 'Emirats Arabes Unis', 'Espagne', 'Estonie', 'Finlande', 'Grande-Bretagne', 'Grèce', 'Géorgie', 'Hong-Kong', 'Hongrie', 'Inde', 'Indonésie', 'Irak', 'Iran', 'Irlande', 'Islande', 'Israël', 'Italie', 'Japon', 'Jordanie', 'kazakhstan', 'Kenya', 'Kosovo', 'Lettonie', 'Liban', 'Lituanie', 'Luxembourg', 'Macédoine', 'Malaisie', 'Maroc', 'Mexique', 'Monténégro', 'Nigéria', 'Norvège', 'Nouvelle-Zélande', 'Pakistan', 'Palestine', 'Pays-Bas', 'Philippines', 'Pologne', 'Portugal', 'Pérou', 'Qatar', 'Roumanie', 'Russie', 'République dominicaine', 'République tchèque', 'Serbie', 'Singapour', 'Slovaquie', 'Slovénie', 'Sri Lanka', 'Suisse', 'Suède', 'Syrie', 'Sénégal', 'Taïwan', 'Tchécoslovaquie', 'Thaïlande', 'Tunisie', 'Turquie', 'Ukraine', 'URSS', 'Uruguay', 'Vietnam', 'Vénézuela', 'Yougoslavie', 'Botswana', 'Namibie', 'Liechtenstein', 'Monaco']\n",
      "Nb pays : 104\n"
     ]
    }
   ],
   "source": [
    "# Scrap all countries\n",
    "elt_countries = elt_categories.find_next_sibling().find_next_sibling()\n",
    "elts_items = elt_countries.find_all('li', class_ = 'filter-entity-item')\n",
    "\n",
    "countries = []\n",
    "for elt_item in elts_items:\n",
    "    countries.append(elt_item.find('span').text.strip())\n",
    "\n",
    "# 'Botswana' is not in the country list but there is a movie with nationality 'Botswana', so we manually add it to the list.\n",
    "#  https://www.allocine.fr/film/fichefilm_gen_cfilm=2577.html\n",
    "if not('Botwana' in countries):\n",
    "    countries.append('Botswana')\n",
    "if not('Namibie' in countries):\n",
    "    countries.append('Namibie')\n",
    "if not('Liechtenstein' in countries):\n",
    "    countries.append('Liechtenstein')\n",
    "if not('Monaco' in countries):\n",
    "    countries.append('Monaco')\n",
    "\n",
    "print(countries)\n",
    "\n",
    "print(\"Nb pays :\", len(countries))\n",
    "ds_countries = pd.Series(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **On scrape les liens redirigeants vers les pages de films par année**\n",
    "\n",
    "**Nous utilisons Selenium**<br>\n",
    "Lors de l'utilisation de Beautiful Soup, certains éléments sont **décorés**, certains liens sont **invisibles**, on ne peut pas directement les scraper.<br>\n",
    "Le contournement trouvé est d'utiliser Selenium qui permet entre autre :\n",
    "- d'utiliser les XPath,\n",
    "- de récupérer tous les élements et non-décorés.\n",
    "\n",
    "On se donne une liste d'années, par exemple [1980, ... 2000]\n",
    "\n",
    "[1980 - 1989] puis [1990 - 1999] ... jusqu'à [2000 - 2009].<br>\n",
    "(cela fait plus de 40000 films et XXX reviews)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Liens visualisés dans l'inspecteur html de Chrome**\n",
    "\n",
    "![links_decades_inspector](images/link_decades_inspector.png)\n",
    "\n",
    "\n",
    "**Liens visualisés avec Beautiful Soup**\n",
    "\n",
    "![link](images/link_decades_bs4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the limit of Beautiful Soup\n",
    "r = requests.get(url_films, auth=('user', 'pass'))\n",
    "if r.status_code != 200:\n",
    "    print(\"url_site error\")\n",
    "    \n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "# print(soup.prettify())\n",
    "\n",
    "elt_decades = elt_categories.find_next_sibling()\n",
    "print(elt_decades.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:02<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year 1979   ----  link https://www.allocine.fr/films/decennie-1970/annee-1979/\n",
      "year 1978   ----  link https://www.allocine.fr/films/decennie-1970/annee-1978/\n",
      "year 1977   ----  link https://www.allocine.fr/films/decennie-1970/annee-1977/\n",
      "year 1976   ----  link https://www.allocine.fr/films/decennie-1970/annee-1976/\n",
      "year 1975   ----  link https://www.allocine.fr/films/decennie-1970/annee-1975/\n",
      "year 1974   ----  link https://www.allocine.fr/films/decennie-1970/annee-1974/\n",
      "year 1973   ----  link https://www.allocine.fr/films/decennie-1970/annee-1973/\n",
      "year 1972   ----  link https://www.allocine.fr/films/decennie-1970/annee-1972/\n",
      "year 1971   ----  link https://www.allocine.fr/films/decennie-1970/annee-1971/\n",
      "year 1970   ----  link https://www.allocine.fr/films/decennie-1970/annee-1970/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Scrap the links of the years\n",
    "\n",
    "# Input: list of years to scrap\n",
    "lst_years_to_scrap = list(range(1970, 1980))\n",
    "\n",
    "# Ou Bien\n",
    "2 fonctions à faire\n",
    "month_to_scrap = 3 # March (current year)\n",
    "\n",
    "lst_decades_to_scrap = list(set([10 * (year // 10) for year in lst_years_to_scrap]))\n",
    "lst_years_to_scrap = [str(year) for year in lst_years_to_scrap]\n",
    "lst_decades_to_scrap = [str(decade) for decade in lst_decades_to_scrap]\n",
    "\n",
    "driver = webdriver.Chrome(options = _options())\n",
    "driver.get(url_films)\n",
    "elts_decades = driver.find_elements(By.XPATH, '/html/body/div[2]/main/section[4]/div[1]/div/div[3]/div[2]/ul/li')\n",
    "\n",
    "dict_year_link = {}\n",
    "for elt_decade in tqdm(elts_decades):\n",
    "    elt_a = elt_decade.find_element(By.TAG_NAME, 'a')\n",
    "    if not(elt_a.get_attribute('title')[:4] in lst_decades_to_scrap):\n",
    "        continue\n",
    "\n",
    "    driver2 = webdriver.Chrome(options = options)\n",
    "    url_decade = elt_a.get_attribute('href').strip()\n",
    "\n",
    "    driver2.get(url_decade)\n",
    "    elts_years = driver2.find_elements(By.XPATH, '/html/body/div[2]/main/section[4]/div[1]/div/div[3]/div[3]/ul/li')\n",
    "\n",
    "    for elt_year in elts_years:\n",
    "        year = elt_year.find_element(By.TAG_NAME, 'a').get_attribute('title').strip()\n",
    "        if year in lst_years_to_scrap:\n",
    "            link = elt_year.find_element(By.TAG_NAME, 'a').get_attribute('href').strip()\n",
    "            dict_year_link[year] = link\n",
    "    driver2.close()\n",
    "\n",
    "for year, url_year in dict_year_link.items():\n",
    "    print(\"year\", year, '  ----  link', url_year)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **On scrape les films à partir des liens vers les années**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pour scraper les directeurs et acteurs nous allons sur la page **casting** du film puis nous scrapons les acteurs principaux représentés dans la mosaïque, ensuite nous scrapons la liste des acteurs secondaires.\n",
    "\n",
    "![all_actors](images/scraping_all_actors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe comment récupérere l'url de la page des films similaires en fonction de la page du film :<br>\n",
    "https://www.allocine.fr/film/fichefilm_gen_cfilm=180.html<br>\n",
    "https://www.allocine.fr/film/fichefilm-180/similaire/<br>\n",
    "\n",
    "Cela suit toujours le même modèle, nous allons pouvoir automatiser cela sans scraper les urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***  Year 1979  ---  Page 1  ***\n",
      "Title: Buffet Froid\n",
      "Title: Les Bronzés font du ski\n",
      "Title: Alien, le huitième passager\n",
      "Title: Apocalypse Now Final Cut\n",
      "Title: I... comme Icare\n",
      "Title: Nosferatu Fantôme de la Nuit\n",
      "Title: Mad Max\n",
      "Title: Stalker\n",
      "Title: L'Evadé d'Alcatraz\n",
      "Title: Le Seigneur des anneaux\n",
      "Title: L'Amour en Fuite\n",
      "Title: Coup de tête\n",
      "Not enough reviews, Do not scrape the movie: Les égouts du paradis\n",
      "Title: Tess\n",
      "Title: Kramer contre Kramer\n",
      "***  Year 1979  ---  Page 2  ***\n",
      "Title: L'Avare\n",
      "Title: Série noire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:36<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 421\u001b[0m\n\u001b[0;32m    417\u001b[0m elt_movies \u001b[38;5;241m=\u001b[39m soup_movies\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmdl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m elt_movie \u001b[38;5;129;01min\u001b[39;00m elt_movies:\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;66;03m# print('---------------------------------------------------------------- ')\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m     status, movie \u001b[38;5;241m=\u001b[39m \u001b[43mscrap_movie\u001b[49m\u001b[43m(\u001b[49m\u001b[43melt_movie\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_Selenium\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m     counter_movies \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReviews\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[1;32mIn[60], line 238\u001b[0m, in \u001b[0;36mscrap_movie\u001b[1;34m(elt_movie, use_Selenium)\u001b[0m\n\u001b[0;32m    236\u001b[0m is_casting_section \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    237\u001b[0m link_casting \u001b[38;5;241m=\u001b[39m elt_end_section[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 238\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_site\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlink_casting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m soup_casting \u001b[38;5;241m=\u001b[39m BeautifulSoup(r\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;66;03m# Get directors' list\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\envs\\block1\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\envs\\block1\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\envs\\block1\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\envs\\block1\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\envs\\block1\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\envs\\block1\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\envs\\block1\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\envs\\block1\\Lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\envs\\block1\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\envs\\block1\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\envs\\block1\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\envs\\block1\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\envs\\block1\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\envs\\block1\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def number_pages_per_year(soup_year):\n",
    "    ''' Return the number of pages for one year'''\n",
    "    pagination = soup_year.find('div', class_='pagination-item-holder')\n",
    "    nb_pages = int(pagination.find_all('span')[-1].text)\n",
    "    return int(nb_pages)\n",
    "\n",
    "def delete_thumbnails():\n",
    "    '''Delete all files in thumbnail directory'''\n",
    "    try:\n",
    "        folder_name = os.getcwd() + '\\\\thumbnails\\\\'\n",
    "        files = os.listdir(folder_name)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(folder_name, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "        print(\"All files deleted successfully.\")\n",
    "    except OSError:\n",
    "        print(\"Error occurred while deleting files.\")\n",
    "\n",
    "def get_title(soup_movie):\n",
    "    ''' Return the title of the movie '''\n",
    "\n",
    "    title = soup_movie.find('div', class_ = \"titlebar-title titlebar-title-xl\").text\n",
    "    elts = soup_movie.find_all('div', class_ = 'meta-body-item')\n",
    "    for elt in elts:\n",
    "        elts_span = elt.find_all('span')\n",
    "        for elt_span in elts_span:\n",
    "            if \"Titre original\" in elt_span.get_text(strip = True):\n",
    "                return title, elt_span.find_next_sibling().get_text(strip = True)\n",
    "    return title, title\n",
    "\n",
    "def get_date_duration_categories(soup_movie):\n",
    "    ''' Return date, duration and categories (as string) of the movie '''\n",
    "    elt = soup_movie.find('div', class_=\"meta-body-item meta-body-info\")\n",
    "    date, duration, categories = '', '', ''\n",
    "    \n",
    "    if False: # Not really accurate\n",
    "        text = elt.get_text(strip=True)\n",
    "        # print(text)\n",
    "        if text.count('|') == 1:\n",
    "            s1, s2 = text.split('|')\n",
    "            categories = s2.strip()\n",
    "        elif text.count('|') == 2:\n",
    "            s1, s2, s3 = text.split('|')\n",
    "            date = s1[:-8].strip()\n",
    "            duration = s2.strip()\n",
    "            categories = s3.strip()\n",
    "        return date, duration, categories\n",
    "\n",
    "    text = elt.get_text(strip = True)\n",
    "    for elt_span in elt.find_all(\"span\"):\n",
    "        if 'date' in elt_span.get('class'):\n",
    "            date = elt_span.get_text(strip = True)\n",
    "            text = text.replace(date, '')\n",
    "\n",
    "        elif 'meta-release-type' in elt_span.get('class'):\n",
    "            text = text.replace(elt_span.get_text(strip = True), '')\n",
    "\n",
    "        elif 'dark-grey-link' in elt_span.get('class'):\n",
    "            categories += elt_span.get_text(strip = True) + ','\n",
    "            for item in elt_span.get_text(strip = True).split():\n",
    "                text = text.replace(item, '')\n",
    "\n",
    "    text = text.replace('|', '')\n",
    "    text = text.replace(',', '')\n",
    "\n",
    "    if categories[-1] == ',':\n",
    "        categories = categories[:-1]\n",
    "\n",
    "    if len(text.strip()):\n",
    "        duration = text.strip()\n",
    "\n",
    "    return date, duration, categories\n",
    "\n",
    "def get_country(soup_movie):\n",
    "    ''' Return country of the movie '''\n",
    "    elts_section_title = soup_movie.find_all('div', class_ = 'section-title')\n",
    "    for elt_section_title in elts_section_title:\n",
    "        elt_h2 = elt_section_title.find('h2')\n",
    "\n",
    "        if elt_h2 and 'Infos techniques' in elt_h2.text.strip():\n",
    "            elt_country = elt_section_title.find_next_sibling()\n",
    "            assert \"Nationalité\" in elt_country.find(\"span\", class_ = \"what light\").text.strip()\n",
    "            elt_span_that = elt_country.find(\"span\", class_ = \"that\")\n",
    "            elts_span_country = elt_span_that.find_all(\"span\")\n",
    "            lst_countries = []\n",
    "            for elt_span_country in elts_span_country:\n",
    "                lst_countries.append(elt_span_country.text.strip())\n",
    "            return ','.join(lst_countries)\n",
    "    return ''\n",
    "\n",
    "def get_directors(soup_casting):\n",
    "    ''' Return list of directors '''\n",
    "    elt_director_section = soup_casting.find('section', class_='section casting-director')\n",
    "    if elt_director_section:\n",
    "        elt_temp = elt_director_section.find_next()\n",
    "        elts_directors = elt_temp.find_next_sibling().find_all('div', class_ = 'card person-card person-card-col')\n",
    "        lst_directors = [elt_director.find('a').text for elt_director in elts_directors]\n",
    "        return ','.join(lst_directors)\n",
    "    return ''\n",
    "\n",
    "def get_actors(soup_casting):\n",
    "    ''' Return list of actors (maximum 30) '''\n",
    "    elt_actor_section = soup_casting.find('section', class_ = 'section casting-actor')\n",
    "    if elt_actor_section:\n",
    "        elt_temp = elt_actor_section.find_next()\n",
    "        # scrap main actors (maximum eight actors in the mosaic, see image above)\n",
    "        elts_actors = elt_temp.find_next_sibling().find_all('div', class_ = 'card person-card person-card-col')\n",
    "        lst_actors = [elt_actor.find('figure').find('span')['title'] for elt_actor in elts_actors]\n",
    "        elts_actors = elt_actor_section.find_all('div', class_ = 'md-table-row')\n",
    "        # scrap list of actors below the mosaic (we scrap maximum of (8 + 22) 30 actors in total)\n",
    "        lst_actors.extend([elt_actor.find('a').text for elt_actor in elts_actors[:22] if elt_actor.find('a')])\n",
    "        return ','.join(lst_actors)\n",
    "    return ''\n",
    "\n",
    "def get_composers(soup_casting):\n",
    "    ''' Scrap the name(s) of the music composer(s) '''\n",
    "    elts_sections = soup_casting.find_all(\"div\", class_ = \"section casting-list-gql\")\n",
    "    for elt_section in elts_sections:\n",
    "        elt_title = elt_section.find('div', class_ = 'titlebar section-title').find('h2')\n",
    "        if 'Soundtrack' in elt_title.text:\n",
    "            lst_composers = []\n",
    "            elts_composers = elt_section.find_all('div', class_ = 'md-table-row')\n",
    "            for elt_composer in elts_composers:\n",
    "                elts_span = elt_composer.find_all('span')\n",
    "                if len(elts_span) > 1 and 'Compositeur' in elts_span[1].text.strip():\n",
    "                    lst_composers.append(elts_span[0].text.strip())\n",
    "            return ','.join(lst_composers)\n",
    "    return ''\n",
    "\n",
    "def get_summary(soup_movie):\n",
    "    elt_synopsis = soup_movie.find('section', class_ = \"section ovw ovw-synopsis\")\n",
    "    if elt_synopsis:\n",
    "        elt_content = elt_synopsis.find('p', class_ = 'bo-p')\n",
    "        if elt_content:\n",
    "            return elt_content.text.strip()\n",
    "    return ''\n",
    "\n",
    "def get_thumbnail(soup_movie):\n",
    "    elt = soup_movie.find('figure', class_ = 'thumbnail')\n",
    "    return elt.span.img['src']\n",
    "\n",
    "def save_thumbnail(title, url_thumbnail):\n",
    "    '''Save the thumbnail as image file in directory \"thumbnails\"'''\n",
    "    try:\n",
    "        folder_name = os.getcwd() + '\\\\thumbnails\\\\'\n",
    "        title2 = title.replace('-', '')\n",
    "        image_name = f\"thumbnail-{title2}.jpg\"\n",
    "        file = open(folder_name + image_name, \"wb\")\n",
    "        image = httpx.get(url_thumbnail)\n",
    "        file.write(image.content)\n",
    "        # Display thumbnail in Jupyter / console\n",
    "        img = Image.open(io.BytesIO(image.content))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        # To change resolution: https://www.geeksforgeeks.org/change-image-resolution-using-pillow-in-python/\n",
    "    except IOError:\n",
    "        print(\"Cannot read the file\")\n",
    "    finally:\n",
    "        file.close()\n",
    "\n",
    "def get_similar_movies(url_similar_movies):\n",
    "    ''' return list of similar movies '''\n",
    "\n",
    "    lst_similar_movies = []\n",
    "    # print('url_similar_movies:', url_similar_movies)\n",
    "\n",
    "    # get the 'similar movies page' soup\n",
    "    r = requests.get(url_similar_movies, auth=('user', 'pass'))\n",
    "    soup_similar_movie = BeautifulSoup(r.content, 'html.parser')\n",
    "    if r.status_code != 200:\n",
    "        return lst_similar_movies\n",
    "    \n",
    "    elts_section = soup_similar_movie.find_all('ul', class_ = \"section\")\n",
    "    if elts_section:\n",
    "        elts_similar_movies = elts_section[0].find_all('li', class_ = 'mdl')\n",
    "        if elts_similar_movies:\n",
    "            for elt_similar_movie in elts_similar_movies:\n",
    "                elt_title = elt_similar_movie.find('h2', class_ = 'meta-title')\n",
    "                lst_similar_movies.append(elt_title.find('a').text.strip())\n",
    "\n",
    "    return lst_similar_movies\n",
    "\n",
    "def scrap_movie(elt_movie, use_Selenium):\n",
    "    ''' scrap all movie informations '''\n",
    "    \n",
    "    # get the movie soup\n",
    "    url_movie = url_site + elt_movie.h2.a.get('href')[1:]\n",
    "    r = requests.get(url_movie, auth=('user', 'pass'))\n",
    "    soup_movie = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    # ------------- #\n",
    "    #     Title     #\n",
    "    # ------------- #\n",
    "    title, original_title = get_title(soup_movie)\n",
    "\n",
    "    # ------------ #\n",
    "    #    Ratings   #\n",
    "    # ------------ #\n",
    "    star_rating, nb_notes, nb_reviews = get_ratings(soup_movie, use_Selenium)\n",
    "    nb_reviews = convert_to_integer(nb_reviews)\n",
    "    if nb_reviews < nb_minimum_critics:\n",
    "        print(\"Not enough reviews, Do not scrape the movie:\" , title)\n",
    "        return 'Reviews', None\n",
    "    \n",
    "    # --------------------------------- #\n",
    "    #   Date, duration and categories   #\n",
    "    # --------------------------------- #\n",
    "    date, duration, categories = get_date_duration_categories(soup_movie)\n",
    "\n",
    "    # We do not scrape 'Documentaries' or movie with only category : Divers\n",
    "    if 'Documentaire' in categories or categories.strip() == 'Divers':\n",
    "        print('We do not scrape those category film:', title)\n",
    "        return 'Category', None\n",
    "    \n",
    "    print('Title:', title)\n",
    "\n",
    "    # ---------------- #\n",
    "    #     Countries    #\n",
    "    # ---------------- #\n",
    "    countries = get_country(soup_movie)\n",
    "\n",
    "    # ---------------------------------- #\n",
    "    #   Directors / Actors / Composers   #\n",
    "    # ---------------------------------- #\n",
    "    directors, actors, composers = '', '', ''\n",
    "    is_casting_section = False\n",
    "    elts_end_section = soup_movie.find_all('a', class_ = 'end-section-link')\n",
    "\n",
    "    if elts_end_section:\n",
    "        for elt_end_section in elts_end_section:\n",
    "\n",
    "            if 'Casting' in elt_end_section['title']:\n",
    "                # If there is a link to the casting section\n",
    "                is_casting_section = True\n",
    "                link_casting = elt_end_section['href']\n",
    "                r = requests.get(url_site + link_casting, auth=('user', 'pass'))\n",
    "                soup_casting = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "                # Get directors' list\n",
    "                directors = get_directors(soup_casting)\n",
    "                # Get actors' list\n",
    "                actors = get_actors(soup_casting)\n",
    "                # Composers' list\n",
    "                composers = get_composers(soup_casting)\n",
    "                break \n",
    "\n",
    "    if not(is_casting_section):\n",
    "        # No casting section\n",
    "        # for example animation movies does not have a casting section\n",
    "        # some movies neither: https://www.allocine.fr/film/fichefilm_gen_cfilm=27635.html\n",
    "\n",
    "        # Get directors' list\n",
    "        elt_director = soup_movie.find('div', class_ = \"meta-body-item meta-body-direction\")\n",
    "        if elt_director:\n",
    "            elts_span = elt_director.find_all('span')\n",
    "            assert len(elts_span) >= 2\n",
    "            directors =  elts_span[1].get_text().strip()\n",
    "            # directors.append(elts_span[1].get_text().strip())\n",
    "\n",
    "        # Get actors' list\n",
    "        elt_actor = soup_movie.find('div', class_ = \"meta-body-item meta-body-actor\")\n",
    "        if elt_actor:\n",
    "            lst_actors = []\n",
    "            for elt_a in elt_actor.find_all('a'):\n",
    "                lst_actors.append(elt_a.text.strip())\n",
    "            actors = ','.join(lst_actors)\n",
    "\n",
    "    # ------------ #\n",
    "    #   Summary    #\n",
    "    # ------------ #\n",
    "    summary = get_summary(soup_movie)[:180]\n",
    "\n",
    "    # ------------ #\n",
    "    #   Thumbnail  #\n",
    "    # ------------ #\n",
    "    url_thumbnail = get_thumbnail(soup_movie)\n",
    "    # save_thumbnail(title, url_thumbnail)\n",
    "\n",
    "    # ------------------- #\n",
    "    #     url_reviews     #\n",
    "    # ------------------- #\n",
    "    url_reviews = url_movie.replace('_gen_cfilm=', '-')[:-5] + '/critiques/spectateurs/'\n",
    "\n",
    "    # ------------------- #\n",
    "    #    Similar Movies   #\n",
    "    # ------------------- #\n",
    "    url_similar_movies = url_movie.replace('_gen_cfilm=', '-')[:-5] + '/similaire/'\n",
    "    # soup_similar_movies\n",
    "    # lst_similar_movies = get_similar_movies(url_similar_movies)\n",
    "    # print(lst_similar_movies)\n",
    "\n",
    "    return 'OK', (title, original_title, date, duration, categories, countries, star_rating, \\\n",
    "                  nb_notes, nb_reviews, directors, actors, composers,\\\n",
    "                  summary, url_thumbnail, url_reviews, url_similar_movies)\n",
    "\n",
    "def get_ratings(soup_movie, use_Selenium):\n",
    "    ''' Scrap the ratings of the movie.\n",
    "\n",
    "        Return:\n",
    "         - stareval:   star rating (0.5 to 5),\n",
    "         - nb_notes:   number of votes,\n",
    "         - nb_reviews: number of reviews (written reviews),\n",
    "\n",
    "        Args:\n",
    "         - soup_movie:   object BeautifulSoup of the movie,\n",
    "         - use_Selenium: boolean to choose the method to scrape,\n",
    "                         True:  Selenium's method,      (SLOWER)\n",
    "                         False: Beautifulsoup's method. (FASTER)\n",
    "    '''\n",
    "\n",
    "    star_rating, nb_notes, nb_reviews = None, None, None\n",
    "\n",
    "    if use_Selenium:\n",
    "        elts_ratings = driver.find_elements(By.CLASS_NAME, 'rating-item')\n",
    "\n",
    "        for elt_rating in elts_ratings:\n",
    "            elt = None\n",
    "            try:\n",
    "                elt = elt_rating.find_element(By.TAG_NAME, 'a')\n",
    "                if 'Spectateurs' in elt.text.strip():\n",
    "                    elt_stareval_note = elt_rating.find_element(By.CLASS_NAME, 'stareval-note')\n",
    "                    star_rating = elt_stareval_note.text.strip()\n",
    "                    elt_stareval_review = elt_rating.find_element(By.CLASS_NAME, 'stareval-review')\n",
    "                    stareval_review = elt_stareval_review.text.strip()\n",
    "                    if stareval_review.count(',') == 1:\n",
    "                        nb_notes, nb_reviews = stareval_review.split(',')\n",
    "                        nb_notes = nb_notes.split()[0]\n",
    "                        nb_reviews = nb_reviews.split()[0]\n",
    "                    elif 'note' in stareval_review:\n",
    "                        nb_notes = stareval_review.strip()\n",
    "                    elif 'critique' in stareval_review:\n",
    "                        nb_reviews = stareval_review\n",
    "                    else:\n",
    "                        assert False\n",
    "\n",
    "            except:\n",
    "                print('no tag \"a\" in elt_rating')\n",
    "\n",
    "    else: # use beautiful soup\n",
    "        elts_ratings = soup_movie.find_all('div', class_ = 'rating-item-content')\n",
    "        for elt_rating in elts_ratings:\n",
    "            if 'Spectateurs' in elt_rating.find(\"span\").text.strip():\n",
    "                elt_stareval_note = elt_rating.find(\"span\", class_ = \"stareval-note\")\n",
    "                star_rating = elt_stareval_note.text.strip()\n",
    "                elt_stareval_review = elt_rating.find(\"span\", class_ = \"stareval-review\")\n",
    "                stareval_review = elt_stareval_review.text.strip()\n",
    "                if stareval_review.count(',') == 1:\n",
    "                    nb_notes, nb_reviews = stareval_review.split(',')\n",
    "                    nb_notes = nb_notes.split()[0]\n",
    "                    nb_reviews = nb_reviews.split()[0]\n",
    "                elif 'note' in stareval_review:\n",
    "                    nb_notes = stareval_review.strip()\n",
    "                elif 'critique' in stareval_review:\n",
    "                    nb_reviews = stareval_review\n",
    "                else:\n",
    "                    assert False\n",
    "\n",
    "    return star_rating, nb_notes, nb_reviews\n",
    "\n",
    "def convert_to_integer(str_nb_reviews):\n",
    "    ''' Convert the string str_nb_reviews into integer '''\n",
    "    ''' USELESS ??? '''\n",
    "    # assert False\n",
    "    if not(str_nb_reviews):\n",
    "        return 0\n",
    "    test = re.search('\\\\d+', str_nb_reviews)\n",
    "    return int(test.string)\n",
    "\n",
    "\n",
    "# ---------------------------------- #\n",
    "#                                    #\n",
    "#             Main loop              #\n",
    "#                                    #\n",
    "# ---------------------------------- #\n",
    "        \n",
    "# loop on all years to scrap (through links previously scrapped)\n",
    "# then loop on all pages of the year\n",
    "# then loop on all movies on one page\n",
    "\n",
    "# delete_thumbnails()\n",
    "\n",
    "nb_minimum_critics = 20\n",
    "nb_consecutives_unpopular_movies_to_break = 20\n",
    "use_Selenium = False\n",
    "\n",
    "# Create Selenium driver\n",
    "driver = None\n",
    "if use_Selenium:\n",
    "    driver = webdriver.Chrome(options = _options())\n",
    "\n",
    "counter_movies                          = 0\n",
    "counter_scraped_movies                  = 0\n",
    "counter_not_scraped_not_enough_reviews  = 0\n",
    "counter_not_scraped_categories          = 0\n",
    "movies = []\n",
    "\n",
    "for year, url_year in tqdm(dict_year_link.items()):\n",
    "    \n",
    "    r = requests.get(url_year, auth=('user', 'pass'))\n",
    "    if r.status_code != 200:\n",
    "        print(\"url_site error\")\n",
    "\n",
    "    soup_year = BeautifulSoup(r.content, 'html.parser')\n",
    "    nb_pages = number_pages_per_year(soup_year)\n",
    "    consecutive_number_of_unpopular_movies = 0\n",
    "\n",
    "    for i in range(nb_pages): # Need to reduce as some movies are totaly unknown with very few informations about\n",
    "        url_year_page = url_year + f'?page={i+1}'\n",
    "        r = requests.get(url_year_page, auth=('user', 'pass'))\n",
    "        if r.status_code != 200:\n",
    "            print(\"url_site error\")\n",
    "\n",
    "        print(f\"***  Year {year}  ---  Page {i+1}  ***\")\n",
    "        soup_movies = BeautifulSoup(r.content, 'html.parser')\n",
    "        elt_movies = soup_movies.find_all('li', class_='mdl')\n",
    "\n",
    "        for elt_movie in elt_movies:\n",
    "            # print('---------------------------------------------------------------- ')\n",
    "            status, movie = scrap_movie(elt_movie, use_Selenium)\n",
    "            counter_movies += 1\n",
    "            \n",
    "            if status == 'Reviews':\n",
    "                counter_not_scraped_not_enough_reviews += 1\n",
    "                consecutive_number_of_unpopular_movies += 1\n",
    "                if consecutive_number_of_unpopular_movies == nb_consecutives_unpopular_movies_to_break:\n",
    "                    # Reached the number of consecutives \"unpopular\" movies so we stop scrapping this year.\n",
    "                    print(f\"Reached {nb_consecutives_unpopular_movies_to_break} consecutives 'unpopular' movies: BREAK\")\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                consecutive_number_of_unpopular_movies = 0 # Reset the number of unpopular movies\n",
    "\n",
    "                if status == 'OK':\n",
    "                    counter_scraped_movies += 1\n",
    "                    movies.append(movie)\n",
    "                else:\n",
    "                    assert status == 'Category'\n",
    "                    counter_not_scraped_categories += 1\n",
    "\n",
    "        if consecutive_number_of_unpopular_movies == nb_consecutives_unpopular_movies_to_break:\n",
    "            # Stop scrapping for this year\n",
    "            break\n",
    "\n",
    "if driver:\n",
    "    driver.close()\n",
    "\n",
    "df_movies = pd.DataFrame(movies, columns = ['title', 'original_title', 'date', 'duration', 'categories', \\\n",
    "                                            'countries', 'star_rating', 'notes', 'reviews', \\\n",
    "                                            'directors', 'actors', 'composers', 'summary', \\\n",
    "                                            'url_thumbnail', 'url_reviews', 'url_similar_movies'])\n",
    "\n",
    "# Display some infos\n",
    "print(\"\\n*** Scrapping summary ***\")\n",
    "print(\"Nb movies scanned: \", counter_movies)\n",
    "print(\"Nb movies scrapped:\", counter_scraped_movies)\n",
    "\n",
    "if counter_not_scraped_not_enough_reviews:\n",
    "    print(\"Not scrapped Reviews: \", counter_not_scraped_not_enough_reviews)\n",
    "if counter_not_scraped_categories:\n",
    "    print(\"Not scrapped Category:  \", counter_not_scraped_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Some results of scrapping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scrapping the year 1980** :<br>\n",
    "We only keep movies with at least 20 critics:\n",
    "\n",
    "![scrapping_year_1980_more_20_critics](images/scrapping_year_1980_critics_more_20.png)\n",
    "\n",
    "We only keep movies with at least 10 critics:\n",
    "\n",
    "![scrapping_year_1980_more_10_critics](images/scrapping_year_1980_critics_more_10.png)\n",
    "\n",
    "**Scrapping the decade 80** :<br>\n",
    "We only keep movies with at least 20 critics:\n",
    "\n",
    "![scrapping_decade_80_more_20_critics](images/scrapping_decade_80_critics_more_20.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>date</th>\n",
       "      <th>duration</th>\n",
       "      <th>categories</th>\n",
       "      <th>countries</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>notes</th>\n",
       "      <th>reviews</th>\n",
       "      <th>directors</th>\n",
       "      <th>actors</th>\n",
       "      <th>composers</th>\n",
       "      <th>summary</th>\n",
       "      <th>url_thumbnail</th>\n",
       "      <th>url_reviews</th>\n",
       "      <th>url_similar_movies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L'Armée des Ombres</td>\n",
       "      <td>L'Armée des Ombres</td>\n",
       "      <td>12 septembre 1969</td>\n",
       "      <td>2h 23min</td>\n",
       "      <td>Drame,Guerre</td>\n",
       "      <td>France,Italie</td>\n",
       "      <td>4,3</td>\n",
       "      <td>8227</td>\n",
       "      <td>299</td>\n",
       "      <td>Jean-Pierre Melville</td>\n",
       "      <td>Lino Ventura,Simone Signoret,Paul Crauchet,Jea...</td>\n",
       "      <td>Éric Demarsan</td>\n",
       "      <td>France 1942. Gerbier, ingénieur des Ponts et C...</td>\n",
       "      <td>https://fr.web.img4.acsta.net/c_310_420/img/23...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-4248/cr...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-4248/si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Easy Rider</td>\n",
       "      <td>Easy Rider</td>\n",
       "      <td>27 juin 1969</td>\n",
       "      <td>1h 34min</td>\n",
       "      <td>Aventure,Drame</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>3,8</td>\n",
       "      <td>8916</td>\n",
       "      <td>349</td>\n",
       "      <td>Dennis Hopper</td>\n",
       "      <td>Peter Fonda,Dennis Hopper,Jack Nicholson,Lea M...</td>\n",
       "      <td></td>\n",
       "      <td>Billy et Captain America disposent d'une gross...</td>\n",
       "      <td>https://fr.web.img3.acsta.net/c_310_420/medias...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-178/cri...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-178/sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Un homme qui me plaît</td>\n",
       "      <td>Un homme qui me plaît</td>\n",
       "      <td>2 septembre 2014</td>\n",
       "      <td>1h 50min</td>\n",
       "      <td>Comédie dramatique</td>\n",
       "      <td>France</td>\n",
       "      <td>3,4</td>\n",
       "      <td>284</td>\n",
       "      <td>38</td>\n",
       "      <td>Claude Lelouch</td>\n",
       "      <td>Jean-Paul Belmondo,Annie Girardot,Maria Pia Co...</td>\n",
       "      <td>Francis Lai</td>\n",
       "      <td>Au cours d'un tournage à Los Angeles, une actr...</td>\n",
       "      <td>https://fr.web.img3.acsta.net/c_310_420/pictur...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-43194/c...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-43194/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Z</td>\n",
       "      <td>Z</td>\n",
       "      <td>26 février 1969</td>\n",
       "      <td>2h 05min</td>\n",
       "      <td>Drame,Historique</td>\n",
       "      <td>Algérie,France</td>\n",
       "      <td>4,1</td>\n",
       "      <td>1541</td>\n",
       "      <td>100</td>\n",
       "      <td>Costa-Gavras</td>\n",
       "      <td>Yves Montand,Jean-Louis Trintignant,Irène Papa...</td>\n",
       "      <td>Mikis Theodorakis</td>\n",
       "      <td>Un député progressiste est assassiné dans un p...</td>\n",
       "      <td>https://fr.web.img6.acsta.net/c_310_420/pictur...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-5493/cr...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-5493/si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Butch Cassidy et le Kid</td>\n",
       "      <td>Butch Cassidy and the Sundance Kid</td>\n",
       "      <td>6 février 1970</td>\n",
       "      <td>1h 50min</td>\n",
       "      <td>Action,Biopic,Western</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>4,1</td>\n",
       "      <td>5704</td>\n",
       "      <td>162</td>\n",
       "      <td>George Roy Hill</td>\n",
       "      <td>Paul Newman,Robert Redford,Katharine Ross,Stro...</td>\n",
       "      <td>Burt Bacharach</td>\n",
       "      <td>Au début du XXe siècle, Butch Cassidy et son a...</td>\n",
       "      <td>https://fr.web.img5.acsta.net/c_310_420/medias...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-559/cri...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-559/sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>L'Inconnu de Las Vegas</td>\n",
       "      <td>Ocean's 11</td>\n",
       "      <td>1 septembre 1961</td>\n",
       "      <td>2h 07min</td>\n",
       "      <td>Comédie,Thriller</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2,9</td>\n",
       "      <td>204</td>\n",
       "      <td>32</td>\n",
       "      <td>Lewis Milestone</td>\n",
       "      <td>Frank Sinatra,Dean Martin,Sammy Davis Jr.,Pete...</td>\n",
       "      <td>Nelson Riddle</td>\n",
       "      <td>Gros casse à Las Vegas. Onze amis vétérans de ...</td>\n",
       "      <td>https://fr.web.img5.acsta.net/c_310_420/medias...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-70321/c...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-70321/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Celui par qui le scandale arrive...</td>\n",
       "      <td>Home from the Hill</td>\n",
       "      <td>mai 1961</td>\n",
       "      <td>2h 30min</td>\n",
       "      <td>Aventure,Drame,Romance</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>4,1</td>\n",
       "      <td>190</td>\n",
       "      <td>25</td>\n",
       "      <td>Vincente Minnelli</td>\n",
       "      <td>Robert Mitchum,Eleanor Parker,George Peppard,G...</td>\n",
       "      <td>Bronislau Kaper</td>\n",
       "      <td>Un grand propriétaire du Sud tyrannise sa femm...</td>\n",
       "      <td>https://fr.web.img2.acsta.net/c_310_420/medias...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-58981/c...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-58981/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Le Diabolique Docteur Mabuse</td>\n",
       "      <td>Die 1000 Augen des Dr. Mabuse</td>\n",
       "      <td>20 juin 1961</td>\n",
       "      <td>1h 43min</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>France,Italie,Allemagne de l'Ouest</td>\n",
       "      <td>3,8</td>\n",
       "      <td>168</td>\n",
       "      <td>31</td>\n",
       "      <td>Fritz Lang</td>\n",
       "      <td>Wolfgang Preiss,Dawn Addams,Peter van Eyck,Ger...</td>\n",
       "      <td>Gerhard Becker</td>\n",
       "      <td>Un journaliste est tué dans sa voiture sur la ...</td>\n",
       "      <td>https://fr.web.img6.acsta.net/c_310_420/pictur...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-81611/c...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-81611/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Les Maîtresses de Dracula</td>\n",
       "      <td>The Brides of Dracula</td>\n",
       "      <td>7 novembre 2017</td>\n",
       "      <td>1h 25min</td>\n",
       "      <td>Epouvante-horreur</td>\n",
       "      <td>Grande-Bretagne</td>\n",
       "      <td>3,4</td>\n",
       "      <td>104</td>\n",
       "      <td>24</td>\n",
       "      <td>Terence Fisher</td>\n",
       "      <td>Peter Cushing,Martita Hunt,Yvonne Monlaur,Fred...</td>\n",
       "      <td>Malcolm Williamson</td>\n",
       "      <td>Marianne a accepté un poste d’institutrice dan...</td>\n",
       "      <td>https://fr.web.img5.acsta.net/c_310_420/pictur...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-47709/c...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-47709/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Les Deux Cavaliers</td>\n",
       "      <td>Two Rode Together</td>\n",
       "      <td>6 octobre 1961</td>\n",
       "      <td>1h 49min</td>\n",
       "      <td>Western</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>3,1</td>\n",
       "      <td>177</td>\n",
       "      <td>30</td>\n",
       "      <td>John Ford</td>\n",
       "      <td>James Stewart,Richard Widmark,Shirley Jones,Li...</td>\n",
       "      <td>George Duning</td>\n",
       "      <td>Le shérif Guthrie McCabe, fumeur et alcoolique...</td>\n",
       "      <td>https://fr.web.img5.acsta.net/c_310_420/medias...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-5141/cr...</td>\n",
       "      <td>https://www.allocine.fr/film/fichefilm-5141/si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   title                      original_title  \\\n",
       "0                     L'Armée des Ombres                  L'Armée des Ombres   \n",
       "1                             Easy Rider                          Easy Rider   \n",
       "2                  Un homme qui me plaît               Un homme qui me plaît   \n",
       "3                                      Z                                   Z   \n",
       "4                Butch Cassidy et le Kid  Butch Cassidy and the Sundance Kid   \n",
       "..                                   ...                                 ...   \n",
       "513               L'Inconnu de Las Vegas                          Ocean's 11   \n",
       "514  Celui par qui le scandale arrive...                  Home from the Hill   \n",
       "515         Le Diabolique Docteur Mabuse       Die 1000 Augen des Dr. Mabuse   \n",
       "516            Les Maîtresses de Dracula               The Brides of Dracula   \n",
       "517                   Les Deux Cavaliers                   Two Rode Together   \n",
       "\n",
       "                  date  duration              categories  \\\n",
       "0    12 septembre 1969  2h 23min            Drame,Guerre   \n",
       "1         27 juin 1969  1h 34min          Aventure,Drame   \n",
       "2     2 septembre 2014  1h 50min      Comédie dramatique   \n",
       "3      26 février 1969  2h 05min        Drame,Historique   \n",
       "4       6 février 1970  1h 50min   Action,Biopic,Western   \n",
       "..                 ...       ...                     ...   \n",
       "513   1 septembre 1961  2h 07min        Comédie,Thriller   \n",
       "514           mai 1961  2h 30min  Aventure,Drame,Romance   \n",
       "515       20 juin 1961  1h 43min                Thriller   \n",
       "516    7 novembre 2017  1h 25min       Epouvante-horreur   \n",
       "517     6 octobre 1961  1h 49min                 Western   \n",
       "\n",
       "                              countries star_rating notes  reviews  \\\n",
       "0                         France,Italie         4,3  8227      299   \n",
       "1                                U.S.A.         3,8  8916      349   \n",
       "2                                France         3,4   284       38   \n",
       "3                        Algérie,France         4,1  1541      100   \n",
       "4                                U.S.A.         4,1  5704      162   \n",
       "..                                  ...         ...   ...      ...   \n",
       "513                              U.S.A.         2,9   204       32   \n",
       "514                              U.S.A.         4,1   190       25   \n",
       "515  France,Italie,Allemagne de l'Ouest         3,8   168       31   \n",
       "516                     Grande-Bretagne         3,4   104       24   \n",
       "517                              U.S.A.         3,1   177       30   \n",
       "\n",
       "                directors                                             actors  \\\n",
       "0    Jean-Pierre Melville  Lino Ventura,Simone Signoret,Paul Crauchet,Jea...   \n",
       "1           Dennis Hopper  Peter Fonda,Dennis Hopper,Jack Nicholson,Lea M...   \n",
       "2          Claude Lelouch  Jean-Paul Belmondo,Annie Girardot,Maria Pia Co...   \n",
       "3            Costa-Gavras  Yves Montand,Jean-Louis Trintignant,Irène Papa...   \n",
       "4         George Roy Hill  Paul Newman,Robert Redford,Katharine Ross,Stro...   \n",
       "..                    ...                                                ...   \n",
       "513       Lewis Milestone  Frank Sinatra,Dean Martin,Sammy Davis Jr.,Pete...   \n",
       "514     Vincente Minnelli  Robert Mitchum,Eleanor Parker,George Peppard,G...   \n",
       "515            Fritz Lang  Wolfgang Preiss,Dawn Addams,Peter van Eyck,Ger...   \n",
       "516        Terence Fisher  Peter Cushing,Martita Hunt,Yvonne Monlaur,Fred...   \n",
       "517             John Ford  James Stewart,Richard Widmark,Shirley Jones,Li...   \n",
       "\n",
       "              composers                                            summary  \\\n",
       "0         Éric Demarsan  France 1942. Gerbier, ingénieur des Ponts et C...   \n",
       "1                        Billy et Captain America disposent d'une gross...   \n",
       "2           Francis Lai  Au cours d'un tournage à Los Angeles, une actr...   \n",
       "3     Mikis Theodorakis  Un député progressiste est assassiné dans un p...   \n",
       "4        Burt Bacharach  Au début du XXe siècle, Butch Cassidy et son a...   \n",
       "..                  ...                                                ...   \n",
       "513       Nelson Riddle  Gros casse à Las Vegas. Onze amis vétérans de ...   \n",
       "514     Bronislau Kaper  Un grand propriétaire du Sud tyrannise sa femm...   \n",
       "515      Gerhard Becker  Un journaliste est tué dans sa voiture sur la ...   \n",
       "516  Malcolm Williamson  Marianne a accepté un poste d’institutrice dan...   \n",
       "517       George Duning  Le shérif Guthrie McCabe, fumeur et alcoolique...   \n",
       "\n",
       "                                         url_thumbnail  \\\n",
       "0    https://fr.web.img4.acsta.net/c_310_420/img/23...   \n",
       "1    https://fr.web.img3.acsta.net/c_310_420/medias...   \n",
       "2    https://fr.web.img3.acsta.net/c_310_420/pictur...   \n",
       "3    https://fr.web.img6.acsta.net/c_310_420/pictur...   \n",
       "4    https://fr.web.img5.acsta.net/c_310_420/medias...   \n",
       "..                                                 ...   \n",
       "513  https://fr.web.img5.acsta.net/c_310_420/medias...   \n",
       "514  https://fr.web.img2.acsta.net/c_310_420/medias...   \n",
       "515  https://fr.web.img6.acsta.net/c_310_420/pictur...   \n",
       "516  https://fr.web.img5.acsta.net/c_310_420/pictur...   \n",
       "517  https://fr.web.img5.acsta.net/c_310_420/medias...   \n",
       "\n",
       "                                           url_reviews  \\\n",
       "0    https://www.allocine.fr/film/fichefilm-4248/cr...   \n",
       "1    https://www.allocine.fr/film/fichefilm-178/cri...   \n",
       "2    https://www.allocine.fr/film/fichefilm-43194/c...   \n",
       "3    https://www.allocine.fr/film/fichefilm-5493/cr...   \n",
       "4    https://www.allocine.fr/film/fichefilm-559/cri...   \n",
       "..                                                 ...   \n",
       "513  https://www.allocine.fr/film/fichefilm-70321/c...   \n",
       "514  https://www.allocine.fr/film/fichefilm-58981/c...   \n",
       "515  https://www.allocine.fr/film/fichefilm-81611/c...   \n",
       "516  https://www.allocine.fr/film/fichefilm-47709/c...   \n",
       "517  https://www.allocine.fr/film/fichefilm-5141/cr...   \n",
       "\n",
       "                                    url_similar_movies  \n",
       "0    https://www.allocine.fr/film/fichefilm-4248/si...  \n",
       "1    https://www.allocine.fr/film/fichefilm-178/sim...  \n",
       "2    https://www.allocine.fr/film/fichefilm-43194/s...  \n",
       "3    https://www.allocine.fr/film/fichefilm-5493/si...  \n",
       "4    https://www.allocine.fr/film/fichefilm-559/sim...  \n",
       "..                                                 ...  \n",
       "513  https://www.allocine.fr/film/fichefilm-70321/s...  \n",
       "514  https://www.allocine.fr/film/fichefilm-58981/s...  \n",
       "515  https://www.allocine.fr/film/fichefilm-81611/s...  \n",
       "516  https://www.allocine.fr/film/fichefilm-47709/s...  \n",
       "517  https://www.allocine.fr/film/fichefilm-5141/si...  \n",
       "\n",
       "[518 rows x 16 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## **Enregistrement des données dans des fichiers cvs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"csv/categories.npy\", ds_categories.array.tolist())\n",
    "# np.save(\"csv/countries.npy\", ds_countries.array.tolist())\n",
    "# ds_categories.to_csv('csv/categories.csv', sep = ',', index=False)\n",
    "# ds_countries.to_csv('csv/countries.csv', sep = ',', index=False)\n",
    "\n",
    "df_movies.to_csv('csv/movies_year_1970_to_1980.csv', sep=',')\n",
    "# df_movies.to_csv('csv/movies_year_1982.csv', sep = ',', index=False)\n",
    "# df_movies.to_csv('csv/movies_year_1981.csv', index=False, sep = ',')\n",
    "# df_movies.to_csv('csv/movies_decade_80.csv', sep = ',')\n",
    "# df_movies.to_csv('csv/movies_decade_90.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Quelques difficultés rencontrées**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le scrapping des \"films similaires\" on récupère simplement la liste des films similaires (leurs titres), ce n'est que lorsque tous les films auront été scrappés et mis dans dans des Dataframe et que leur seront attribués des Ids (clés de tables de base de données) que nous pourrons associer un film aux Ids des films similaires.\n",
    "\n",
    "Remarque :\n",
    "Il n'a pas été possible de trouver d'informations sur la méthode utilisée par \"allocine.com\" pour composer la liste de films similaires à un film, il n'apparait pas de liens clairs entre les catégories de films, ni entre les acteurs, il est possible que ce soit un algorithme d'IA qui soit à la base de ce choix ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "block1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
